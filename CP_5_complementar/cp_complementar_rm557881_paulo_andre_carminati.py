# -*- coding: utf-8 -*-
"""CP_complementar_rm557881_paulo_andre_carminati.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qrIeXYTF_tGHmZ5v3tQ1ZynEgDJ9Z0_x
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import joblib

file_path = '/content/drive/MyDrive/Colab Notebooks/CP/CP_complementar/wine_quality_general.csv.xlsx'
df = pd.read_excel(file_path)

"""### Análise Exploratória
#### Análise descritiva das características
- Distribuição de cada característica
- Observação sobre a coluna `color_wine` (1 indica vinho branco e 2 indica vinho tinto)
- Verificação da distribuição da variável `quality`

5. Análise de Distribuição
"""

# Estatísticas descritivas básicas
df.describe()

# Visualização das distribuições das características
for col in df.columns[:-1]:
    plt.figure(figsize=(10, 4))
    # Especifica um número razoável de bins para evitar problemas de binning automático
    sns.histplot(df[col], kde=True, bins=20)  # Alterado aqui
    plt.title(f'Distribuição de {col}')
    plt.show()

"""6. Verificação de Outliers

"""

# Boxplot para detectar outliers
plt.figure(figsize=(15, 8))
sns.boxplot(data=df)
plt.title('Boxplot de todas as características')
plt.show()

"""7. Divisão dos Dados

"""

# Separação das variáveis independentes e dependentes
X = df.drop('quality', axis=1)
y = df['quality']

# Divisão dos dados
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

"""### Modelagem de Classificação
#### Modelos escolhidos:
- Regressão Logística
- Random Forest
- Máquina de Vetores de Suporte (SVM)

"""

# Treinando o modelo de Regressão Logística
log_reg = LogisticRegression(max_iter=1000)
log_reg.fit(X_train, y_train)

"""Modelo 2: Random Forest"""

# Treinando o modelo Random Forest
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

"""Modelo 3: SVM"""

# Treinando o modelo de SVM
svm_model = SVC()
svm_model.fit(X_train, y_train)

"""9. Avaliação de Desempenho"""

# Avaliando o desempenho de cada modelo

# Regressão Logística
y_pred_log_reg = log_reg.predict(X_test)
print("Relatório de classificação - Regressão Logística")
print(classification_report(y_test, y_pred_log_reg))
print("Acurácia:", accuracy_score(y_test, y_pred_log_reg))

# Random Forest
y_pred_rf = rf.predict(X_test)
print("Relatório de classificação - Random Forest")
print(classification_report(y_test, y_pred_rf))
print("Acurácia:", accuracy_score(y_test, y_pred_rf))

# SVM
y_pred_svm = svm_model.predict(X_test)
print("Relatório de classificação - SVM")
print(classification_report(y_test, y_pred_svm))
print("Acurácia:", accuracy_score(y_test, y_pred_svm))

"""10. Confusão de Classes"""

# Matriz de Confusão para cada modelo
print("Matriz de Confusão - Regressão Logística")
print(confusion_matrix(y_test, y_pred_log_reg))

print("Matriz de Confusão - Random Forest")
print(confusion_matrix(y_test, y_pred_rf))

print("Matriz de Confusão - SVM")
print(confusion_matrix(y_test, y_pred_svm))

"""11. Seleção do Melhor Modelo

### Melhor Modelo
Com base nas métricas de precisão, recall, F1-score e acurácia, o modelo X foi selecionado como o melhor modelo. Justificativa:

12. Salvando o Melhor Modelo
"""

# Salvando o modelo
joblib.dump(rf, 'melhor_modelo_rf.pkl')

"""13. Carregando e Fazendo Nova Previsão"""

# Carregando o modelo salvo
melhor_modelo = joblib.load('melhor_modelo_rf.pkl')

# Criando novos dados de exemplo (conforme as colunas do dataset original)
novos_dados = pd.DataFrame({
    'fixed acidity': [7.0],
    'volatile acidity': [0.27],
    'citric acid': [0.36],
    'residual sugar': [2.07],
    'chlorides': [0.045],
    'free sulfur dioxide': [45],
    'total sulfur dioxide': [170],
    'density': [1.001],
    'pH': [3.0],
    'sulphates': [0.45],
    'alcohol': [8.8],
    'tipo': [1]
})

# Fazendo a previsão
previsao = melhor_modelo.predict(novos_dados)
print("Nova previsão:", previsao)

"""Matriz De Correlação Das Características"""

# Gerar matriz de correlação
correlation_matrix = df.corr()

# Plotar o mapa de calor da matriz de correlação
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Mapa de Calor da Correlação entre as Variáveis")
plt.show()

"""Código para Detecção de Outliers usando IQR"""

# Detectar outliers usando o método de IQR (Interquartile Range)
Q1 = df.quantile(0.25)
Q3 = df.quantile(0.75)
IQR = Q3 - Q1

# Identificando outliers em todo o DataFrame
outliers = ((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).sum()
print("Número de outliers por coluna:")
print(outliers)

# Removendo outliers (opcional)
df_no_outliers = df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]

"""Divisão de Dados: Atualização"""

# Separação das variáveis independentes e dependentes após remoção de outliers
X = df_no_outliers.drop('quality', axis=1)
y = df_no_outliers['quality']

# Divisão dos dados
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

"""Treinamento dos Modelos"""

# Treinamento da Regressão Logística
log_reg = LogisticRegression(max_iter=1000)
log_reg.fit(X_train, y_train)

# Treinamento da Random Forest
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# Treinamento da SVM
svm_model = SVC()
svm_model.fit(X_train, y_train)

"""Avaliação de Desempenho

"""

# Função para avaliar o desempenho de um modelo
def avaliar_modelo(nome_modelo, modelo, X_test, y_test):
    y_pred = modelo.predict(X_test)
    print(f"Relatório de classificação - {nome_modelo}")
    print(classification_report(y_test, y_pred))
    print(f"Acurácia: {accuracy_score(y_test, y_pred)}")

    # Matriz de confusão
    cm = confusion_matrix(y_test, y_pred)

    # Imprime a matriz de confusão diretamente
    print(f"Matriz de Confusão:\n{cm}\n")

    # Remova a tentativa de desempacotar os valores da matriz de confusão
    # como tn, fp, fn, tp, pois isso só funciona para classificação binária.
    # Em problemas multi-classe, a matriz de confusão tem mais dimensões.
    # Para obter informações detalhadas sobre FP, FN, etc., você pode
    # acessar os elementos da matriz 'cm' diretamente usando indexação.
    # Por exemplo, cm[0, 1] acessaria o elemento na primeira linha e segunda coluna.


# Avaliando cada modelo
avaliar_modelo("Regressão Logística", log_reg, X_test, y_test)
avaliar_modelo("Random Forest", rf, X_test, y_test)
avaliar_modelo("SVM", svm_model, X_test, y_test)

"""Código para Salvar o Melhor Modelo

"""

# Salvando o modelo escolhido (neste exemplo, Random Forest)
joblib.dump(rf, 'melhor_modelo_rf.pkl')

"""Código para Carregar e Prever"""

# Carregando o modelo salvo
melhor_modelo = joblib.load('melhor_modelo_rf.pkl')

# Criando novos dados de exemplo
novos_dados = pd.DataFrame({
    'fixed acidity': [7.0],
    'volatile acidity': [0.27],
    'citric acid': [0.36],
    'residual sugar': [2.07],
    'chlorides': [0.045],
    'free sulfur dioxide': [45],
    'total sulfur dioxide': [170],
    'density': [1.001],
    'pH': [3.0],
    'sulphates': [0.45],
    'alcohol': [8.8],
    'tipo': [1]
})

# Fazendo a previsão
previsao = melhor_modelo.predict(novos_dados)
print("Nova previsão:", previsao)

# Verificando a importância das características no modelo de Random Forest

# Extraindo a importância das características
importances = rf.feature_importances_

# Criando um DataFrame para exibir as características e suas importâncias
feature_importance_df = pd.DataFrame({
    'Feature': X.columns,
    'Importance': importances
}).sort_values(by='Importance', ascending=False)

# Plotando a importância das características
plt.figure(figsize=(12, 6))
sns.barplot(x='Importance', y='Feature', data=feature_importance_df, palette='viridis')
plt.title("Importância das Características no Modelo de Random Forest")
plt.show()

# Exibir as importâncias em formato tabular
feature_importance_df

## calculo das estatísticas detalhadas:

# Estatísticas detalhadas do DataFrame original (ou df_no_outliers se necessário)
detailed_stats = df.describe().transpose()

# Adicionando métricas adicionais
detailed_stats['median'] = df.median()
detailed_stats['variance'] = df.var()
detailed_stats['skewness'] = df.skew()
detailed_stats['kurtosis'] = df.kurt()

# Exibir estatísticas detalhadas
detailed_stats

# Geração dos Gráficos de Dispersão

# Criar gráficos de dispersão entre as variáveis principais e a variável de qualidade

# Definindo as colunas para criar os gráficos de dispersão
columns_to_plot = df.columns[:-1]  # Excluindo a última coluna 'quality'

# Plotando gráficos de dispersão
plt.figure(figsize=(20, 15))
for i, col in enumerate(columns_to_plot, 1):
    plt.subplot(4, 3, i)
    sns.scatterplot(x=col, y='quality', data=df, hue='tipo', palette='coolwarm')
    plt.title(f'Dispersão entre {col} e Quality')

plt.tight_layout()
plt.show()

"""Regressão Linear Entre Tipo E Quality

Interpretação dos Resultados:
Gráficos de Regressão Linear: Para cada variável, é mostrado um gráfico com a linha de regressão em vermelho. Esses gráficos indicam como cada característica individualmente se relaciona linearmente com a variável quality.
Coeficientes do Modelo: Uma tabela foi gerada mostrando o coeficiente de cada característica no modelo de regressão linear, indicando a contribuição de cada uma para a previsão da qualidade. Coeficientes positivos indicam uma influência positiva, enquanto os negativos indicam uma influência negativa na qualidade.
"""

from sklearn.linear_model import LinearRegression

# Criar um modelo de Regressão Linear para cada característica individual em relação à qualidade
plt.figure(figsize=(20, 15))
for i, col in enumerate(columns_to_plot, 1):
    plt.subplot(4, 3, i)
    sns.regplot(x=col, y='quality', data=df, line_kws={"color": "red"})
    plt.title(f'Regressão Linear entre {col} e Quality')

plt.tight_layout()
plt.show()

# Treinando um modelo de Regressão Linear utilizando todas as características
X_all = df.drop('quality', axis=1)
y_all = df['quality']

linear_model = LinearRegression()
linear_model.fit(X_all, y_all)

# Exibindo os coeficientes de cada característica
coefficients = pd.DataFrame({
    'Feature': X_all.columns,
    'Coefficient': linear_model.coef_
}).sort_values(by='Coefficient', ascending=False)

# Exibindo a tabela de coeficientes
coefficients

# Calculando assimetria (skewness) e curtose (kurtosis) para cada coluna
skewness = df.skew()
kurtosis = df.kurt()

# Criando um DataFrame para exibir os resultados
skewness_kurtosis_df = pd.DataFrame({
    'Feature': df.columns,
    'Skewness': skewness,
    'Kurtosis': kurtosis
})

# Exibindo o DataFrame
skewness_kurtosis_df

"""VALIDAÇÃO CRUZADA:

1. Importação da Biblioteca de Validação Cruzada

2. Aplicando Validação Cruzada k-Folds
"""

from sklearn.model_selection import cross_val_score

# Definindo k para a validação cruzada
k = 5

# Modelos treinados
modelos = {
    "Regressão Logística": LogisticRegression(max_iter=1000),
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "SVM": SVC()
}

# Loop para calcular a validação cruzada de cada modelo
for nome_modelo, modelo in modelos.items():
    scores = cross_val_score(modelo, X_all, y_all, cv=k, scoring='accuracy')
    print(f"{nome_modelo}: Acurácia Média de Validação Cruzada = {scores.mean():.4f} (Desvio Padrão = {scores.std():.4f})")

"""Aplicar GridSearchCV"""

# ipython-input-39-8e26a0d0e3e0 (Execute this cell first)
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV

# Definindo os grids de hiperparâmetros para cada modelo
param_grid_logreg = {
    'C': [0.1, 1, 10, 100]
}

param_grid_rf = {
    'n_estimators': [50, 100, 200],
    'max_depth': [5, 10, 20]
}

param_grid_svm = {
    'C': [0.1, 1, 10, 100],
    'kernel': ['linear', 'rbf', 'poly']
}

# Criando instâncias dos modelos
log_reg = LogisticRegression(max_iter=1000)
rf = RandomForestClassifier(random_state=42)
svm_model = SVC()

# Criando os objetos GridSearchCV para cada modelo
grid_search_logreg = GridSearchCV(log_reg, param_grid_logreg, cv=5, scoring='accuracy')
grid_search_rf = GridSearchCV(rf, param_grid_rf, cv=5, scoring='accuracy')
grid_search_svm = GridSearchCV(svm_model, param_grid_svm, cv=5, scoring='accuracy')

# Aplicando o GridSearchCV em cada modelo
grid_search_logreg.fit(X_train, y_train) # Assuming X_train and y_train are defined
grid_search_rf.fit(X_train, y_train)    # Assuming X_train and y_train are defined
grid_search_svm.fit(X_train, y_train)   # Assuming X_train and y_train are defined

# Exibindo os melhores parâmetros encontrados para cada modelo
print("Melhores parâmetros para Regressão Logística:", grid_search_logreg.best_params_)
print("Melhores parâmetros para Random Forest:", grid_search_rf.best_params_)
print("Melhores parâmetros para SVM:", grid_search_svm.best_params_)

# Treinando os modelos com os melhores parâmetros
melhor_logreg = grid_search_logreg.best_estimator_
melhor_rf = grid_search_rf.best_estimator_
melhor_svm = grid_search_svm.best_estimator_

# Avaliando os modelos otimizados
print("Acurácia da Regressão Logística Otimizada:", melhor_logreg.score(X_test, y_test)) # Assuming X_test and y_test are defined
print("Acurácia da Random Forest Otimizada:", melhor_rf.score(X_test, y_test))    # Assuming X_test and y_test are defined
print("Acurácia da SVM Otimizada:", melhor_svm.score(X_test, y_test))   # Assuming X_test and y_test are defined

"""Checklist Final de Melhoria
1 Análise de Balanceamento de Dados:
"""

from imblearn.over_sampling import SMOTE

smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_train, y_train)

"""2 Avaliação com Curvas ROC-AUC:"""

# ipython-input-46-8e26a0d0e3e0 (Execute this cell after the previous one)
import matplotlib.pyplot as plt # Import matplotlib for plotting
from sklearn.metrics import roc_auc_score, roc_curve

# Now you can use 'melhor_rf' as it has been defined in the previous cell
y_proba = melhor_rf.predict_proba(X_test)[:, 1]  # Para modelo binário
fpr, tpr, _ = roc_curve(y_test, y_proba)
plt.plot(fpr, tpr, label="Modelo Random Forest")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("Curva ROC")
plt.legend()
plt.show()

# Assuming 'X_train', 'y_train' are defined in a previous cell
from sklearn.ensemble import RandomForestClassifier
import shap

# 1. Train your Random Forest model:
melhor_rf = RandomForestClassifier(random_state=42) # Or your preferred parameters
melhor_rf.fit(X_train, y_train)

# 2. Then run your SHAP analysis:
explainer = shap.TreeExplainer(melhor_rf)
shap_values = explainer.shap_values(X_test)

# 3. Plot the results:
shap.summary_plot(shap_values, X_test)